{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6dda47c5",
   "metadata": {},
   "source": [
    "---\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62029f86",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    "\n",
    "> This module contains the optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ee96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3507a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def gradient_descent(x:np.ndarray, # x data of N elements\n",
    "                     y:np.ndarray, # y data of N elements\n",
    "                     pini:dict, # initial parameters of the loss function\n",
    "                     ll:dict, # dictionary with the loss ('loss'), the gradients ('grads') and the function ('fun') for the regression/classification\n",
    "                     niter=int(1E3), #number of iterations\n",
    "                     eta=1E-3, #learning rate\n",
    "                    )->dict:#dictionary containing the vector of the losses ('loss') and the parameters (following the keys of pini)\n",
    "    \n",
    "    loss, grads, fun = ll['loss'] , ll['grads'], ll['fun']\n",
    "    \n",
    "    trackers = {}\n",
    "    trackers['loss'] = [loss(x,y,fun,pini)]\n",
    "    for p in pini: trackers[p] = [pini[p]]\n",
    "    \n",
    "    params = deepcopy(pini)\n",
    "    for i in range(niter):\n",
    "        g= grads(x,y,params)\n",
    "        trackers['loss'] = trackers['loss']+ [loss(x,y,fun,params)]\n",
    "        for i,p in enumerate(params): \n",
    "            trackers[p] = trackers[p]+ [trackers[p][-1]-eta*g[i]]\n",
    "            params[p] = trackers[p][-1]\n",
    "    return trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39777ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sgd_epoch(x:np.ndarray, # x data of N elements\n",
    "              y:np.ndarray, # y data of N elements\n",
    "              pini:dict, # initial parameters of the loss function\n",
    "              ll:dict, # dictionary with the loss ('loss'), the gradients ('grads') and the function ('fun') for the regression/classification\n",
    "              bs=10, #Batch size\n",
    "              eta=1E-3 #learning rate\n",
    "             )->dict:#dictionary containing the vector of the losses ('loss') and the parameters (following the keys of pini) \n",
    "    mask = np.arange(y.size)\n",
    "    np.random.shuffle(mask)\n",
    "    nb = y.size//bs\n",
    "    lb = np.mod(y.size,bs)\n",
    "    \n",
    "    loss, grads, fun = ll['loss'] , ll['grads'], ll['fun']\n",
    "    \n",
    "    trackers = {}\n",
    "    trackers['loss'] = [loss(x,y,fun,pini)]\n",
    "    for p in pini: trackers[p] = [pini[p]]\n",
    "\n",
    "    params = deepcopy(pini)\n",
    "    for i in range(nb):\n",
    "        m = mask[i*bs:(i+1)*bs]\n",
    "        if np.size(x.shape)==1:\n",
    "            xx, yy = x[m], y[m]\n",
    "        else:\n",
    "            xx, yy = x[m,:], y[m]\n",
    "        g= grads(xx,yy,params)\n",
    "        trackers['loss'] = trackers['loss']+ [loss(x,y,fun,params)]\n",
    "        for i,p in enumerate(params): \n",
    "            trackers[p] = trackers[p]+ [trackers[p][-1]-eta*g[i]]\n",
    "            params[p] = trackers[p][-1]\n",
    "    return trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sgd(x:np.ndarray, # x data of N elements\n",
    "        y:np.ndarray, # y data of N elements\n",
    "        pini:dict, # initial parameters of the loss function\n",
    "        ll:dict, # dictionary with the loss ('loss'), the gradients ('grads') and the function ('fun') for the regression/classification\n",
    "        bs=10, #Batch size\n",
    "        eta=1E-3, #learning rate\n",
    "        niter=int(1E3) #number of epochs\n",
    "        )->dict:#dictionary containing the vector of the losses ('loss') and the parameters (following the keys of pini) \n",
    "    params = deepcopy(pini)\n",
    "    for i in range(niter):\n",
    "        track = sgd_epoch(x, y, params, ll, bs=bs, eta=eta)\n",
    "        if i==0: \n",
    "            trackers = track\n",
    "        else:\n",
    "            for i,p in enumerate(trackers): trackers[p] = trackers[p]+ track[p]\n",
    "        for i,p in enumerate(params): params[p] = trackers[p][-1]\n",
    "    return trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a5109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344e252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
